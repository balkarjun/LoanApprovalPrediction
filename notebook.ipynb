{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f583d8b7-c49d-46ff-93cc-2344f85f0182",
   "metadata": {},
   "source": [
    "# Summary\n",
    "The following are a summary of the results from EDA (Exploratory Data Analysis), preprocessing, classifier comparisons and the final model. More details are provided in the relevant sections.\n",
    "\n",
    "- The dataset needed to be heavily engineered to be made useful for analysis. Due to the nature of the problem, explainability was a primary focus.\n",
    "- The missing values - which were very high in number - were significant predictors. For instance, applications with a missing \"Marital Status\", \"Employment Type\" or \"Asset Cost\" were very likely to be declined.\n",
    "- Features that carried very little significance (like the digital presence features) were ignored, since they provided only a minor increase in performance at the cost of increased complexity. The final model used only 10 engineered features.\n",
    "- Distinguishing between APPROVED and DECLINED classes was important, so **F1 Score** was chosen as the primary metric. **Accuracy** was used as a secondary metric.\n",
    "- 20% of the training data was sampled for validation, with stratification on \"Application Status\" to ensure similar distribution of target across train and validation sets.\n",
    "- Simple interpretable models were favored over complex ones. The baseline One-Rule model (which uses only 1 feature) achieved an F1 Score of 0.8646 and Accuracy of ~84% on the validation set.\n",
    "- The final model (Decision Tree) achieved an F1 Score of **0.9023** and Accuracy of ~**87%** on the validation set.\n",
    "- Visualization of the Decision Tree is provided for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e1ff1-fff3-4540-b640-95910862b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262b19c-2ca7-4920-8a54-ab9dbb971c10",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683f4ae-e992-42b9-8897-5be122650493",
   "metadata": {},
   "source": [
    "## (EDA 1 of 3) Data Description\n",
    "There are 10,000 rows of training data, and 2000 rows of test data, each having 55 columns. Test data has an additional **UID** column in place of the target **Application Status**.\n",
    "\n",
    "*Note: During preliminary analysis, It was found that most features had a similar distribution in both the training and testing set. This analysis is limited to just the training set, to simulate the situation where test data might not be available ahead of time. Most insights will still apply to both.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5337cd1-1e82-403a-abb3-b94f0cd32057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "num_duplicates = train.duplicated().sum()\n",
    "train.drop_duplicates(inplace=True)\n",
    "print(f'Shape (Train): {train.shape[0]} rows, {train.shape[1]} columns (after removal of {num_duplicates} duplicates)')\n",
    "print(f'Shape  (Test): {test.shape[0]} rows, {test.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2d441-22d3-466a-b606-aa172ed9cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(dataset):\n",
    "    # indices will be column names\n",
    "    desc = pd.DataFrame(index = list(dataset))\n",
    "    desc['type'] = dataset.dtypes\n",
    "    desc['count'] = dataset.count()\n",
    "    desc['nunique'] = dataset.nunique()\n",
    "    desc['null'] = dataset.isna().sum()\n",
    "    desc['%null'] = (desc['null'] / len(dataset)) * 100\n",
    "    desc['min'] = dataset.min(numeric_only=True)\n",
    "    desc['max'] = dataset.max(numeric_only=True)\n",
    "    \n",
    "    return desc.T\n",
    "\n",
    "# get_summary(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2ac63-9676-40c0-83cc-8569c3cfe551",
   "metadata": {},
   "source": [
    "There are a large number of missing values. The white gaps in the plot below indicate the location of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3897f-d740-4565-8697-ee2941518329",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(train, figsize=(10, 4), sparkline=False, fontsize=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a2a77-5aea-4262-a116-6815c4ce58e2",
   "metadata": {},
   "source": [
    "There is an imbalance in the target classes *APPROVED* (67%) and *DECLINED* (33%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7fa0a-9311-4882-9eb3-009f54ef7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to build pie charts\n",
    "def get_pie_data(data):\n",
    "    value_counts = data.value_counts()\n",
    "    return list(value_counts.index), list(value_counts.values)\n",
    "\n",
    "labels, values = get_pie_data(train['Application Status'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.pie(values, labels=labels, autopct='%1.0f%%')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18a5c7-bd17-4bfc-8b02-5731a5257a4e",
   "metadata": {},
   "source": [
    "None of the Aadhaars were verified but all mobile numbers were verified. These features provide no value and will not be used for the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08de00e-b7b5-4166-877b-2fd249e6bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_aadhaar = int((train['AADHAR VERIFIED'] != 'NO').mean() * 100)\n",
    "verified_mobile = int((train['MOBILE VERIFICATION']).mean() * 100)\n",
    "print(f\"Verified Aadhaars: {verified_aadhaar}%\")\n",
    "print(f\"Verified Mobile Numbers: {verified_mobile}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf84ae-d0d4-495c-94d3-9ce18554d811",
   "metadata": {},
   "source": [
    "The term **approval rate** is used to refer to the ratio of approved samples to total samples. This provided a useful way to compare different groups of data.\n",
    "$$\\text{Approval Rate} = \\frac{\\text{No. of Approved Applications}}{\\text{No. of Declined Applications}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57187a82-64b5-4e13-8e68-4e195a9c8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make approval rate calculation easier\n",
    "train['target'] = train['Application Status'].map({'APPROVED': 1, 'DECLINED': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b87690-131f-4018-95b2-a3761081eb1e",
   "metadata": {},
   "source": [
    "Given the nature of the dataset and the class imbalance, **F1 Score** will be used as the primary metric and **Accuracy** as a secondary metric to measure model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813b566-3133-416b-a931-1db24aba5970",
   "metadata": {},
   "source": [
    "## (EDA 2 of 3) Loan Application Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f764e23-1b7e-40a2-88ee-50e84ffb6951",
   "metadata": {},
   "source": [
    "All applications were submitted between 03 July 2022 to 31 July 2022, with between 217 to 505 applications per day. There is a clear pattern in number of applications across days, with the lowest daily applications on weekends. There is no discernable difference in approval rates across days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7cead-7c83-4d8e-824a-d017c5f0c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# date strings have mixed formats (07/20/2022, 07/04/22 etc.)\n",
    "dates = pd.to_datetime(train.groupby('APPLICATION LOGIN DATE').size().keys(), format='mixed')\n",
    "counts = train.groupby('APPLICATION LOGIN DATE').size().values\n",
    "\n",
    "ax.plot(dates, counts, linewidth=2.5)\n",
    "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b %d'))\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('No. of Applications')\n",
    "ax.set_title('No. of Applications by Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf5a05-595e-4f4e-b95b-12d9bbebff9e",
   "metadata": {},
   "source": [
    "Most application were from **Uttar Pradesh**. Haryana, Bihar and Uttar Pradesh account for 37% of all applications. Approval rates are roughly identical across states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1ef5f-974e-4b7b-8897-cd3baf17db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to build pareto charts\n",
    "def get_pareto_data(data, column, threshold=None):\n",
    "    df = data[[column, 'target']].copy()\n",
    "\n",
    "    # group categories with frequency less than threshold\n",
    "    if threshold is not None:\n",
    "        value_counts = df[column].value_counts()\n",
    "        others = list(value_counts[value_counts <= threshold].index)\n",
    "        df.loc[df[column].isin(others), column] = 'Other'\n",
    "\n",
    "    num_approved = df.groupby(column)['target'].sum().values\n",
    "    num_declined = df.groupby(column)['target'].size().values - num_approved\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'category': df.groupby(column).size().keys().str.title(),\n",
    "        'approved': num_approved,\n",
    "        'declined': num_declined,\n",
    "        'total': num_approved + num_declined\n",
    "    })\n",
    "    data = data.sort_values(by='total', ascending=False)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47b639-41fc-477a-bcf6-f07848099207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_pareto_data(train, 'HDB BRANCH STATE', threshold=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(data['category'], data['approved'], label='Approved')\n",
    "ax.bar(data['category'], data['declined'], bottom=data['approved'], label='Declined')\n",
    "\n",
    "ax.set_xlabel('States')\n",
    "ax.set_ylabel('No. of Applications')\n",
    "ax.set_title('No. of Approved vs Declined Applications by State')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527b349-8a3f-46ed-9488-c1263c4b172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to truncate axis labels\n",
    "def format_func(categories, max_length=10):\n",
    "    def inner(x, pos):\n",
    "        label = categories[pos]\n",
    "        return label if len(label) < max_length else f'{label[:max_length]}...'\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898fa6a-69d2-4290-a552-e316d63c078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "data_maker = get_pareto_data(train, 'PRIMARY ASSET MAKE', threshold=250)\n",
    "data_model = get_pareto_data(train, 'Primary Asset Model No', threshold=500)\n",
    "\n",
    "for idx, data in enumerate([data_maker, data_model]):\n",
    "    ax[idx].bar(data['category'], data['approved'], label='Approved')\n",
    "    ax[idx].bar(data['category'], data['declined'], bottom=data['approved'], label='Declined')\n",
    "\n",
    "    ax[idx].set_ylabel('No. of Applications')\n",
    "    ax[idx].xaxis.set_label_position('top')\n",
    "    ax[idx].xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(format_func(data['category'].reset_index(drop=True))))\n",
    "    ax[idx].legend()\n",
    "\n",
    "    for tick in ax[idx].get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "\n",
    "ax[0].set_xlabel('Manufacturer')\n",
    "ax[1].set_xlabel('Two-Wheeler Model Name')\n",
    "fig.suptitle('No. of Approved vs Declined Applications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062decec-2d77-4336-bbaa-c13b3c563a98",
   "metadata": {},
   "source": [
    "There are 2416 unique dealers. 75% of dealers sold at most 5 two-wheelers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73045ffb-413d-4082-8be5-519969376406",
   "metadata": {},
   "source": [
    "51% of values in two-wheeler category (**ASSET CTG**) and cost (**TOTAL ASSET COST**) are missing. All applications without a missing value in these columns were approved. Applications with missing values in these columns have a very low approval rate (35%). Missing values in asset category correspond to missing values in asset cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee0801-e9f1-4ad0-9333-7c4cb7f62af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with ESNRB category, which only has 1 value\n",
    "drop_idx = train.loc[train['ASSET CTG'] == 'ESNRB'].index[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "sns.violinplot(data=train.drop(drop_idx), x='TOTAL ASSET COST', y='ASSET CTG', split=True, inner='quart', cut=0, fill=False, ax=ax)\n",
    "ax.set_title('Distribution of Asset Cost by Category')\n",
    "ax.set_ylabel('Asset Category')\n",
    "ax.set_xlabel('Asset Cost (Log Scale)')\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd789bd-71a6-47f8-9cca-30ccdb0d6bf5",
   "metadata": {},
   "source": [
    "Ideally, the difference between applied loan amount and the two-wheeler cost should be small. But there are instances with large differences, like row 7650, where the applied amount is ₹14,20,000, for a two-wheeler that costs ₹1,42,723, an error possibly made by a mistype. The Z-score was used to detect such anomalies, using the threshold ±3. That is, any value that is 3 standard deviations away from the mean will be treated as an outlier. This matches what is found by visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7159af-556d-4024-a743-e23a89b662c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_delta = (train['APPLIED AMOUNT'] - train['TOTAL ASSET COST']) / train['TOTAL ASSET COST']\n",
    "price_delta = price_delta.dropna()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "z_scores = (price_delta - price_delta.mean()) / price_delta.std()\n",
    "\n",
    "inliers = z_scores[z_scores.between(-3, 3)]\n",
    "outliers = z_scores[~z_scores.between(-3, 3)]\n",
    "\n",
    "ax.scatter(inliers.index, inliers, label='Inliers', alpha=0.5)\n",
    "ax.scatter(outliers.index, outliers, label='Outliers')\n",
    "\n",
    "ax.set_xlabel('Application Index')\n",
    "ax.set_ylabel('Price Delta')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c718d-43ae-448c-9f02-7cc88506fc0e",
   "metadata": {},
   "source": [
    "Regardless of the extreme values, all the above applications were approved. In fact, as stated earlier, *all* applications that had an asset cost specified, were approved.\n",
    "Given this information, it is more beneficial to use **TOTAL ASSET COST** as an indicator variable (whether it is missing or not). There is limited value in clipping or removing these outliers.\n",
    "\n",
    "For instances where the asset cost is not known (\\~51% of the data), we cannot make a strong judgement using just the applied amount. This was verified using *Welch's t-test* and the corresponding p-value, which shows that the small difference in the mean value of applied amount across classes is not statistically significant. As such, **APPLIED AMOUNT** will not be used as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d61774-fdce-4c32-b784-99483a863196",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "approved_cost = train.loc[train['TOTAL ASSET COST'].isna() & (train['target'] == 1), 'APPLIED AMOUNT']\n",
    "declined_cost = train.loc[train['TOTAL ASSET COST'].isna() & (train['target'] == 0), 'APPLIED AMOUNT']\n",
    "\n",
    "# Welch's t-test (one-sided)\n",
    "result = ttest_ind(approved_cost, declined_cost, equal_var=False, alternative='less')\n",
    "print(f't-statistic: {result.statistic:.4f}')\n",
    "print(f'p-value: {result.pvalue:.4f}')\n",
    "\n",
    "sns.kdeplot(approved_cost, ax=ax, cut=0, label='Approved')\n",
    "sns.kdeplot(declined_cost, ax=ax, cut=0, label='Declined')\n",
    "ax.axvline(approved_cost.mean(), linestyle='--', color='C0', alpha=0.5, label='Mean (Approved)')\n",
    "ax.axvline(declined_cost.mean(), linestyle='--', color='C1', alpha=0.5, label='Mean (Declined)')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Applied Amount (Log Scale)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabb9b9-2741-43e1-91d9-48d949f3d08c",
   "metadata": {},
   "source": [
    "## EDA (3 of 3) Applicant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4f3af-3b62-4dea-8f8e-37460ee91cc1",
   "metadata": {},
   "source": [
    "Employment details are very strong indicators of approval status. The missing values are significant, and should not be removed or imputed without consideration. Nearly all applications with a valid **EMPLOYER TYPE** were approved. Those with missing values for this column have a very low approval rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af58ec-ba4c-4df8-ac2a-33ca2147dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EMPLOYER_TYPE_FILLED'] = train['EMPLOYER TYPE'].fillna('MISSING')\n",
    "data = get_pareto_data(train.copy(), 'EMPLOYER_TYPE_FILLED')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(data['category'], data['approved'], label='Approved')\n",
    "ax.bar(data['category'], data['declined'], bottom=data['approved'], label='Declined')\n",
    "\n",
    "ax.set_title('No. of Approved vs Declined Applications by Employer Type')\n",
    "ax.set_xlabel('Employer Type')\n",
    "ax.set_ylabel('No. of Applications')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ce53a-d0ed-4e9c-8364-847413551de4",
   "metadata": {},
   "source": [
    "There are many duplicates in **EMPLOYER NAME**, like \"Agriculture\", which is mentioned multiple types with different spellings.\n",
    "**EMPLOY CONSTITUTION** is the same as **EMPLOYER TYPE**, with the subtle difference that the Non-Government and Government categories have been merged into the Salaried category.\n",
    "\n",
    "Due to their similarity, and the significance of missing values, only a missing indicator for **EMPLOYER TYPE** will be used during model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0ae76-3934-43e4-8724-6d318ec554e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EMPLOYER NAME'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77035f0d-c185-4d3a-be57-1690eae39570",
   "metadata": {},
   "source": [
    "The **Cibil Score** column has a mix of numerical, string and missing values. The two string values \"NO RESPONSE\" and \"-\" were very few in number, and were treated as missing values. Considering just the numerical values, applications with higher cibil scores were more likely to be approved. A missing indicator will also be used for this feature.\n",
    "\n",
    "A large difference is observed between the mean cibil score across the two classes. Welch's t-test and the corresponding p-value confirm the significance of this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f20dc-31d4-4162-94e3-f60547cfa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing cibil score (numerical) and target (binary/categorical)\n",
    "numerical = train[train['Cibil Score'].apply(lambda x: isinstance(x, str) and x.isdigit())][['Cibil Score', 'target']]\n",
    "numerical['Cibil Score'] = numerical['Cibil Score'].astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "approved_cbscore = numerical.loc[numerical['target'] == 1, 'Cibil Score']\n",
    "declined_cbscore = numerical.loc[numerical['target'] == 0, 'Cibil Score']\n",
    "\n",
    "# Welch's t-test (one-sided)\n",
    "result = ttest_ind(approved_cbscore, declined_cbscore, equal_var=False, alternative='greater')\n",
    "print(f't-statistic: {result.statistic:.4f}')\n",
    "print(f'p-value: {result.pvalue:.4f}')\n",
    "\n",
    "sns.kdeplot(approved_cbscore, label='Approved', ax=ax)\n",
    "sns.kdeplot(declined_cbscore, label='Declined', ax=ax)\n",
    "ax.axvline(approved_cbscore.mean(), linestyle='--', color='C0', alpha=0.5, label='Mean (Approved)')\n",
    "ax.axvline(declined_cbscore.mean(), linestyle='--', color='C1', alpha=0.5, label='Mean (Declined)')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7254bd2-bb15-4aef-9707-94aaabbdc956",
   "metadata": {},
   "source": [
    "Most applicants were Male and there was no significant difference in approval rates between Male and Female applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc67d29-8aa5-45b1-be47-20dbecd81adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, values = get_pie_data(train['GENDER'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "ax.pie(values, labels=labels, autopct='%1.0f%%')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645ddd1-78af-43f8-a2a2-1546caf3aa96",
   "metadata": {},
   "source": [
    "Applicants with missing or \"Residence\" address types were far more likely to be rejected than the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fadef6-fbc0-40f0-a70c-5032d87b972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ADDRESS_TYPE_FILLED'] = train['ADDRESS TYPE'].fillna('MISSING')\n",
    "data = get_pareto_data(train.copy(), 'ADDRESS_TYPE_FILLED', threshold=10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(data['category'], data['approved'], label='Approved')\n",
    "ax.bar(data['category'], data['declined'], bottom=data['approved'], label='Declined')\n",
    "\n",
    "ax.set_title('No. of Approved vs Declined Applications by Address Type')\n",
    "ax.set_xlabel('Address Type')\n",
    "ax.set_ylabel('No. of Applications')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379b009-d6de-40d9-be96-b3d2ec43df4d",
   "metadata": {},
   "source": [
    "The zero values in **AGE** are missing values. Since date of birth **DOB** does not have missing values, we can calculate the age based on date of birth and application data to fill the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8ded6-8857-4d63-b3a1-4ce80cbbd89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_age_from_dob(df, default=0):\n",
    "    count = 0\n",
    "    apply_dates = pd.to_datetime(df['APPLICATION LOGIN DATE'], format='mixed')\n",
    "    for index, dob in df.loc[df['AGE'] == 0, 'DOB'].items():\n",
    "        if pd.isnull(dob):\n",
    "            df.loc[index, 'AGE'] = default\n",
    "            continue\n",
    "        date_birth = datetime.strptime(str(dob), '%d%m%Y')\n",
    "        date_applied = apply_dates[index]\n",
    "        year_diff = date_applied.year - date_birth.year\n",
    "        offset = (date_applied.month, date_applied.day) < (date_birth.month, date_birth.day)\n",
    "\n",
    "        age = year_diff - offset\n",
    "        df.loc[index, 'AGE'] = age\n",
    "        count += 1\n",
    "    print(f'Imputed {count} missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c67cf-d2e4-4225-b7e7-82bce1991c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "approved_age_before = train.loc[train['target'] == 1, 'AGE']\n",
    "declined_age_before = train.loc[train['target'] == 0, 'AGE']\n",
    "\n",
    "apply_age_from_dob(train)\n",
    "approved_age_after = train.loc[train['target'] == 1, 'AGE']\n",
    "declined_age_after = train.loc[train['target'] == 0, 'AGE']\n",
    "\n",
    "# Welch's t-test (two-sided)\n",
    "result = ttest_ind(approved_age_after, declined_age_after, equal_var=False)\n",
    "print(f't-statistic: {result.statistic:.4f}')\n",
    "print(f'p-value: {result.pvalue:.4f}')\n",
    "\n",
    "for idx, (approved, declined) in enumerate([(approved_age_before, declined_age_before), (approved_age_after, declined_age_after)]):\n",
    "    sns.kdeplot(approved, label='Approved', ax=ax[idx])\n",
    "    sns.kdeplot(declined, label='Declined', ax=ax[idx])\n",
    "\n",
    "    ax[idx].axvline(approved.mean(), linestyle='--', color='C0', alpha=0.5)\n",
    "    ax[idx].axvline(declined.mean(), linestyle='--', color='C1', alpha=0.5)\n",
    "\n",
    "    ax[idx].set_xlabel('Age')\n",
    "    ax[idx].legend()\n",
    "\n",
    "ax[0].set_title('Before Imputation')\n",
    "ax[1].set_title('After Imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f401f-a619-473d-8274-a1d5c8e5805a",
   "metadata": {},
   "source": [
    "After imputation, the high p-value indicates that this feature is insignificant. But there is a difference in the range of values across the two classes. Applicants younger than 21 years or older than 68 years had their applications declined. This is explained by the fact that most loan providers have age-limits beyond which they do not provide loans. This range is usually 21 to 65, but the upper end of the range is more relaxed in this case. This information is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb902720-7193-499a-a6cd-be57b2437fdb",
   "metadata": {},
   "source": [
    "Applicants with missing **MARITAL STATUS** were more likely to have their applications declined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e953fe-167e-4f47-8aa8-604331deb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "train['MARITAL_STATUS_FILLED'] = train['MARITAL STATUS'].fillna('MISSING')\n",
    "data = get_pareto_data(train, 'MARITAL_STATUS_FILLED')\n",
    "\n",
    "ax.bar(data['category'], data['approved'], label='Approved')\n",
    "ax.bar(data['category'], data['declined'], bottom=data['approved'], label='Declined')\n",
    "\n",
    "ax.set_title('No. of Approved vs Declined Applications by Marital Status')\n",
    "ax.set_ylabel('No. of Applications')\n",
    "ax.set_xlabel('Marital Status')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1af299-3a54-453c-aea1-ca368186a9d5",
   "metadata": {},
   "source": [
    "Low values of **phone_nameMatchScore** indicate severe mismatch between the names obtained (or missing UPI name in several cases). Higher values indicate near-perfect matches, with only minor differences in initials and such. **-1** seems to be a special value, with a near perfect match in most cases, but missing UPI values. These should be treated separately, if the feature is used. \n",
    "\n",
    "More than half the values are extreme values (-1 or 100). Lower approval rates are observed for match scores less than 40, and higher approval rates for match scores greater than 40. But near-perfect match scores show no discernable difference between approved and declined cases. For these reasons, match score will not be used as a feature. **phone_digital** and **phone_phoneFootprintStrengthOverall** will also not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219cd30-e985-4ec6-9d1a-fb145989c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(train, index):\n",
    "    first_name = train.loc[index, 'FIRST NAME']\n",
    "    middle_name = train.loc[index, 'MIDDLE NAME']\n",
    "    last_name = train.loc[index, 'LAST NAME']\n",
    "    last_name = '' if pd.isnull(last_name) else last_name\n",
    "\n",
    "    full_name = None\n",
    "    if not pd.isnull(middle_name):\n",
    "        full_name = f'{first_name} {middle_name} {last_name}'.strip()\n",
    "    else:\n",
    "        full_name = f'{first_name} {last_name}'.strip()\n",
    "    \n",
    "    pan_name = train.loc[index, 'Pan Name']\n",
    "    pan_name = '-' if pd.isnull(pan_name) else pan_name\n",
    "    application_name = train.loc[index, 'name']\n",
    "    upi_name = train.loc[index, 'upi_name']\n",
    "    upi_name = '-' if pd.isnull(upi_name) else upi_name\n",
    "\n",
    "    return f'{full_name} | {pan_name} | {application_name} | {upi_name}'\n",
    "\n",
    "print('EXAMPLES          : Full Name | Pan Name | name | upi_name')\n",
    "print(f'Match Score  (-1) : {get_name(train, 9068)}')\n",
    "print(f'Match Score  (-1) : {get_name(train, 3683)}')\n",
    "print(f'Match Score  (35) : {get_name(train, 1200)}')\n",
    "print(f'Match Score  (78) : {get_name(train, 7419)}')\n",
    "print(f'Match Score (100) : {get_name(train, 9879)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b87144-3729-4dbb-94f9-adb5fb17b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_match_score = train.loc[train['target'] == 1, 'phone_nameMatchScore']\n",
    "declined_match_score = train.loc[train['target'] == 0, 'phone_nameMatchScore']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.kdeplot(approved_match_score, label='Approved', cut=0, ax=ax[0])\n",
    "sns.kdeplot(declined_match_score, label='Declined', cut=0, ax=ax[0])\n",
    "\n",
    "ax[0].axvline(approved_match_score.mean(), linestyle='--', color='C0', alpha=0.5)\n",
    "ax[0].axvline(declined_match_score.mean(), linestyle='--', color='C1', alpha=0.5)\n",
    "ax[0].legend()\n",
    "\n",
    "approved_digitalage = train.loc[train['target'] == 1, 'phone_digitalage']\n",
    "declined_digitalage = train.loc[train['target'] == 0, 'phone_digitalage']\n",
    "\n",
    "sns.kdeplot(approved_digitalage, label='Approved', cut=0, ax=ax[1])\n",
    "sns.kdeplot(declined_digitalage, label='Declined', cut=0, ax=ax[1])\n",
    "\n",
    "ax[1].axvline(approved_digitalage.mean(), linestyle='--', color='C0', alpha=0.5)\n",
    "ax[1].axvline(declined_digitalage.mean(), linestyle='--', color='C1', alpha=0.5)\n",
    "ax[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f7d54-d57b-4d3e-8912-604b42b218e2",
   "metadata": {},
   "source": [
    "There are 20 social media features, most of which have over 50% missing values. Typically, this information would be useful. For example, the presence of certain apps, like gambling apps, might be an important indicator of the applicant's financial habits. But the values for these apps in the dataset were almost entirely missing. \n",
    "\n",
    "Regardless of whether a feature's value is missing, present (1) or absent (0), there is little to no difference in the approval rate. Due to their low significance, and the added complexity, these features will not be used during model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e37412-1690-498f-96f9-1e98240ff7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "social_media_features = [col for col in train.columns if col.startswith('Phone Social Premium')]\n",
    "apps = [x.split('.')[1] for x in social_media_features]\n",
    "\n",
    "rates = []\n",
    "npresent, nabsent, nmissing = np.zeros(len(apps)), np.zeros(len(apps)), np.zeros(len(apps))\n",
    "for idx, feature in enumerate(social_media_features):\n",
    "    present, absent, missing = (train[feature] == 1), (train[feature] == 0), (train[feature].isna())\n",
    "    \n",
    "    npresent[idx] = present.sum()\n",
    "    nabsent[idx]  = absent.sum()\n",
    "    nmissing[idx] = missing.sum()\n",
    "    \n",
    "    rate_present = train.loc[present, 'target'].mean()\n",
    "    rate_absent  = train.loc[absent, 'target'].mean()\n",
    "    rate_missing = train.loc[missing, 'target'].mean()\n",
    "\n",
    "    rates.append([rate_present, rate_absent, rate_missing])\n",
    "\n",
    "# offsets for present, absent and missing bars\n",
    "offsets = (np.zeros(len(apps)), npresent, np.array(nabsent) + np.array(npresent))\n",
    "bars_present = ax.bar(apps, npresent, bottom=offsets[0], label='Present (1)')\n",
    "bars_absent  = ax.bar(apps, nabsent,  bottom=offsets[1], label='Absent (0)')\n",
    "bars_missing = ax.bar(apps, nmissing, bottom=offsets[2], label='Missing', color='lightgray')\n",
    "\n",
    "for i, bars in enumerate(list(zip(bars_present, bars_absent, bars_missing))):\n",
    "    for j, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        xpos = bar.get_x() + bar.get_width() / 2\n",
    "        ypos = offsets[j][i] + height / 2\n",
    "\n",
    "        text = '' if (pd.isnull(rates[i][j]) or (height < 300)) else f'{rates[i][j]:.2f}'\n",
    "        \n",
    "        plt.text(xpos, ypos, text, ha='center', va='center', color='black')\n",
    "\n",
    "ax.set_title('No. of Applications with Missing, Present or Absent Values for Social Media Presence')\n",
    "ax.set_ylabel('No. of Applications')\n",
    "ax.set_xlabel('App Names')\n",
    "ax.legend(loc='upper left')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f8eff-3dda-4e16-863e-d4aeb06e8ca0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d04b1-b48d-49db-9e61-338206952733",
   "metadata": {},
   "source": [
    "Preprocessing was done using the insights from EDA. Due to the large number of missing values, and their significance, many of the features are missing value indicators. 20% of the training data is kept for validation. The data was stratified on \"Application Status\" to ensure that both training and validation set had the same distribution of target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8be52-6fff-48a2-ae5c-5a8f9bb5c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "\n",
    "original_cols = df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941a397-8791-4ba9-bbb8-dfaa16131180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 20% of the data for validation, ensuring that it has the same distribution of targets as training set\n",
    "train, valid = train_test_split(df_train, test_size=0.2, shuffle=True, random_state=42, stratify=df_train['Application Status'])\n",
    "\n",
    "print(f'Train: {train.shape[0]} rows, {train.shape[1]} columns')\n",
    "print(f'Test : {valid.shape[0]} rows, {valid.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36fd8e-4370-439a-b7a2-471e6f627ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in age\n",
    "apply_age_from_dob(train)\n",
    "apply_age_from_dob(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfaad3-b9bb-4e83-9cde-5a009ed455d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cibil scores have a mix of numerical (stored as string), string and missing values.\n",
    "# convert numerical strings to int, and treat all other values as missing values\n",
    "def transform_cibil_score(x):\n",
    "    if isinstance(x, str) and x.isdigit():\n",
    "        return int(x)\n",
    "    return np.nan\n",
    "\n",
    "# group address types into these four categories\n",
    "address_categories = ['missing', 'residence', 'owned_parental_rented', 'other']\n",
    "def transform_address(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'missing'\n",
    "    if x == 'RESIDENCE':\n",
    "        return 'residence'\n",
    "    if x in ('Self/Spouse Owned', 'Parental', 'Rented'):\n",
    "        return 'owned_parental_rented'\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200eafa-783f-468e-b8cd-7e610d7fb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test):\n",
    "    # binary encoding for gender\n",
    "    gender_map = {'Male': 1, 'Female': 0}\n",
    "    train['gender'] = train['GENDER'].map(gender_map)\n",
    "    test['gender'] = test['GENDER'].map(gender_map)\n",
    "\n",
    "    # add missing indicators for asset cost, marital status and employment status\n",
    "    old_cols = ['TOTAL ASSET COST', 'MARITAL STATUS', 'EMPLOYER TYPE']\n",
    "    new_cols = ['asset_cost_missing', 'marital_status_missing', 'employ_missing']\n",
    "    train[new_cols] = train[old_cols].isna().astype(int)\n",
    "    test[new_cols] = test[old_cols].isna().astype(int)\n",
    "\n",
    "    # treat non-numerical cibil scores as missing\n",
    "    train['cibil_score'] = train['Cibil Score'].apply(transform_cibil_score)\n",
    "    test['cibil_score'] = test['Cibil Score'].apply(transform_cibil_score)\n",
    "    # min-max scale cibil scores that are not missing\n",
    "    scaler = MinMaxScaler()\n",
    "    train['cibil_score'] = scaler.fit_transform(train[['cibil_score']])\n",
    "    test['cibil_score'] = scaler.transform(test[['cibil_score']])\n",
    "    # add indicator for missing cibil score\n",
    "    train['cibil_missing'] = train['cibil_score'].isna().astype(int)\n",
    "    test['cibil_missing'] = test['cibil_score'].isna().astype(int)\n",
    "    # fill missing cibil scores with -1\n",
    "    train['cibil_score'] = train['cibil_score'].fillna(-1)\n",
    "    test['cibil_score'] = test['cibil_score'].fillna(-1)\n",
    "\n",
    "    # 1 if age is outside the range [21, 68], 0 otherwise\n",
    "    train['age_outlier'] = (~train['AGE'].between(21, 68)).astype(int)\n",
    "    test['age_outlier'] = (~test['AGE'].between(21, 68)).astype(int)\n",
    "\n",
    "    # one-hot encode address type\n",
    "    def address_concat(x, cat):\n",
    "        return 'address_' + cat\n",
    "        \n",
    "    train_address = train['ADDRESS TYPE'].apply(transform_address).values.reshape(-1, 1)\n",
    "    test_address = test['ADDRESS TYPE'].apply(transform_address).values.reshape(-1, 1)\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=int, drop=['other'], feature_name_combiner=address_concat)\n",
    "    train[encoder.get_feature_names_out()] = encoder.fit_transform(train_address)\n",
    "    test[encoder.get_feature_names_out()] = encoder.transform(test_address)\n",
    "\n",
    "    target_map = {'APPROVED': 1, 'DECLINED': 0}\n",
    "    train['target'] = train['Application Status'].map(target_map)\n",
    "\n",
    "    # if 'test' is a validation set\n",
    "    if 'Application Status' in test.columns:\n",
    "        test['target'] = test['Application Status'].map(target_map)\n",
    "    \n",
    "    return train.drop(columns=original_cols), test.drop(columns=original_cols, errors='ignore')\n",
    "\n",
    "train, valid = preprocess(train, valid)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e40a9-8545-45da-a653-15fb2aae895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Memory Usage (Train):', train.memory_usage().sum()//1024, 'KB')\n",
    "print('Memory Usage (Valid):', valid.memory_usage().sum()//1024, 'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3e78f-cd31-49f3-997a-2c893add410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "y_train = train['target']\n",
    "\n",
    "X_valid = valid.drop(columns=['target'])\n",
    "y_valid = valid['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82841a-3e13-405c-aed8-37df72beb059",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a97283-9c1a-415d-9cf4-176543139310",
   "metadata": {},
   "source": [
    "## One-Rule Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb9b07-0cb1-49a8-af5e-75141cf9a22f",
   "metadata": {},
   "source": [
    "Due to the high predictive power of the missing categories, the simplest of classifiers was used to set a baseline. The One-Rule classifier uses a single feature value (rule) to make the prediction. The missing indication for Marital Status provided the most effective rule:\n",
    "$$\\text{\\textbf{Declined} if Marital Status is missing, else \\textbf{Approved}}$$\n",
    "This simple rule can predict approval status with **~84%** accuracy, with an F1-Score of **0.8646**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c624c86-276f-4a84-8e22-c34b79569657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asset_cost_missing is another potential candidate, with a perfect precision score (but worse recall, and overall worse f1-score)\n",
    "preds = 1 - X_valid['marital_status_missing'] \n",
    "\n",
    "baseline_accuracy = accuracy_score(y_valid, preds)\n",
    "baseline_f1score = f1_score(y_valid, preds)\n",
    "print(f'F1 Score: {baseline_f1score:.4f}')\n",
    "print(f'Accuracy: {baseline_accuracy:.4f}')\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_valid, preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09012cc0-ef43-4bb8-806c-d54d5acb9c59",
   "metadata": {},
   "source": [
    "## Classifier Comparison\n",
    "Various classifiers were compared to find a good balance between interpretability and predictive power. Given the large number of binary features, it would be fair to assume that a Decision Tree classifier (that can easily make splits on these features) would perform well. The comparison shows that this is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f79a6-72fb-4029-86fe-2312cab26c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=0)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42, max_depth=5)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42, max_depth=6, n_estimators=60))\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    score_f1 = f1_score(y_valid, preds)\n",
    "    score_accuracy = accuracy_score(y_valid, preds)\n",
    "\n",
    "    print(f'F1 Score: {score_f1:.4f}, Accuracy: {score_accuracy:.4f} ({name})')\n",
    "    ax.scatter(['F1 Score', 'Accuracy'], [score_f1, score_accuracy], label=name, s=100)\n",
    "\n",
    "ax.scatter(['F1 Score', 'Accuracy'], [baseline_f1score, baseline_accuracy], label='Baseline', color='black', s=100, marker='^')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6205d38-a212-4b57-954e-0bbeba6a984c",
   "metadata": {},
   "source": [
    "Although the Random Forest had slightly higher accuracy and F1-Score, the **Decision Tree**  was chosen as the final model due to its simplicity and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b516d6-5eaa-43ee-ac77-16c9c5f6725f",
   "metadata": {},
   "source": [
    "# Final Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21224086-3ed0-4a72-a3a5-f3af5ed5f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e69539-d591-4af9-a461-a285545a4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: {train.shape[0]} rows, {train.shape[1]} columns')\n",
    "print(f'Test : {test.shape[0]} rows, {test.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cefe0-c092-4353-b2c3-7ae45dcd50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = preprocess(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151e89e-e22c-46d6-b787-d0b38632e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "y_train = train['target']\n",
    "X_test = test.drop(columns=['UID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02af20-f713-4e34-8ce8-cb37d1bf9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "final_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd0713-8c65-434d-b285-471b41f05254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(40, 10))\n",
    "# plot_tree(clf, feature_names=X_train.columns, class_names=['DECLINED', 'APPROVED'], rounded=True, filled=True, proportion=True, ax=ax, fontsize=11)\n",
    "# plt.savefig('decision_tree.png', dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51524e77-e1be-443c-8224-43a694d37407",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_preds = pd.DataFrame({\n",
    "    'UID': test['UID'],\n",
    "    'Prediction': final_preds\n",
    "})\n",
    "mapped_preds['Prediction'] = mapped_preds['Prediction'].map({1: 'APPROVED', 0: 'DECLINED'})\n",
    "mapped_preds['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9e5e2-09c9-4e10-9410-86519f803dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_preds.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "author": "Arjun Balakrishnan",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
